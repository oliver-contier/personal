<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8"/>
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
    <meta content="" name="description"/>
    <meta content="" name="author"/>
    <title>Oliver Contier</title>
    <link href="assets/img/favicon_turtle.png" rel="icon" type="image/x-icon"/>
    <!-- Font Awesome icons (free version)-->
    <script crossorigin="anonymous" src="https://use.fontawesome.com/releases/v5.13.0/js/all.js"></script>
    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet"
          type="text/css"/>
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css"/>
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet"/>
</head>
<body id="page-top">
<!-- Navigation-->
<nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
    <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">Oliver Contier</span>
        <span class="d-none d-lg-block"><img alt=""
                                             class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile_square.png"/></span>
    </a>
    <button aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler"
            data-target="#navbarSupportedContent" data-toggle="collapse" type="button"><span
            class="navbar-toggler-icon"></span></button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav">
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#currentposition">Current Position</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contributions">Contributions</a></li>
            <!-- <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#cv">Download CV</a></li> -->
            <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#blog">Blog</a></li>
        </ul>
    </div>
</nav>
<!-- Page Content-->
<div class="container-fluid p-0">
    <!-- About-->
    <section class="resume-section" id="about">
        <div class="resume-section-content">
            <h1 class="mb-0">
                Oliver
                <span class="text-primary">Contier</span>
            </h1>
            <div class="subheading mb-5">
                Stephanstr. 1A · Leipzig, Germany
                <!--<a href="mailto:oliver.contier@maxplanckschools.de">oliver.contier@maxplanckschools.de</a>-->
            </div>
            <p class="lead mb-3">

                I am interested in how the human brain manages to represent the visual world we find ourselves in.
                Recent advances in cognitive neuroscience provide exciting tools to map the structure of the physical
                world to patterns of brain activity.
                This has put scientific models of mental representation within reach - yet our knowledge is still
                expanding and shifting constantly.
            </p>
            <p class="lead mb-3">
                I am currently a PhD student in the
                <a href="https://www.hebartlab.com" target="_blank">Vision and Computational Cognition lab</a>
                at the
                <a href="https://www.cbs.mpg.de/independent-research-groups/vision-and-computational-cognition" target="_blank">
                  Max Planck Institute for Human Cognitive and Brain Sciences</a> in Leipzig, Germany.
                  Along with this, I am also a doctoral candidate within the cross-institutional graduate program
                  <a href="https://www.maxplanckschools.de/en/cognition" target="_blank">Max Planck School of Cognition</a>.
            </p>
            <p class="lead mb-3">
                Another focus of mine lies in using and contributing to <a href="http://centerforopenneuroscience.org/"
                                                                           target="_blank">frameworks that promote
                reproducibility, transparency, and general best practice in the analysis of neuroimaging data</a>
                (specifically fMRI).
            </p>
            <p class="lead mb-5">
                Beyond all things neuroscience, I love computers, books, jazz guitar, and <a HREF="assets/img/klaus.jpg"
                                                                                             target="_blank">my
                friendly dinosaur</a>.
            </p>
            <div class="social-icons">
                <a class="social-icon" href="mailto:oliver.contier@maxplanckschools.de" target="_blank"><i
                        class="fa fa-envelope"></i></a>
                <a class="social-icon" href="https://twitter.com/OliverContier" target="_blank"><i
                        class="fab fa-twitter"></i></a>
                <a class="social-icon" href="https://github.com/oliver-contier/" target="_blank"><i
                        class="fab fa-github"></i></a>
                <a class="social-icon" href="https://www.linkedin.com/in/oliver-contier/" target="_blank"><i
                        class="fab fa-linkedin-in"></i></a>
                <a class="social-icon" href="https://www.researchgate.net/profile/Oliver_Contier" target="_blank"><i
                        class="fab fa-researchgate"></i></a>
                <!-- orcid id logo from png-->
                <a class="social-icon" href="https://orcid.org/0000-0002-2983-4709" target="_blank">
                    <img class="img-responsive" height="28" src="assets/img/ORCIDiD_iconbw128x128.png" width="28"/>
                </a>
            </div>
        </div>
    </section>

    <hr class="m-0"/>
    <!-- Experience-->
    <!--<section class="resume-section" id="experience">
        <div class="resume-section-content">
            <h2 class="mb-5">Experience</h2>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Senior Web Developer</h3>
                    <div class="subheading mb-3">Intelitec Solutions</div>
                    <p>Bring to the table win-win survival strategies to ensure proactive domination. At the end of the day, going forward, a new normal that has evolved from generation X is on the runway heading towards a streamlined cloud solution. User generated content in real-time will have multiple touchpoints for offshoring.</p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">March 2013 - Present</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Web Developer</h3>
                    <div class="subheading mb-3">Intelitec Solutions</div>
                    <p>Capitalize on low hanging fruit to identify a ballpark value added activity to beta test. Override the digital divide with additional clickthroughs from DevOps. Nanotechnology immersion along the information highway will close the loop on focusing solely on the bottom line.</p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">December 2011 - March 2013</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Junior Web Designer</h3>
                    <div class="subheading mb-3">Shout! Media Productions</div>
                    <p>Podcasting operational change management inside of workflows to establish a framework. Taking seamless key performance indicators offline to maximise the long tail. Keeping your eye on the ball while performing a deep dive on the start-up mentality to derive convergence on cross-platform integration.</p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">July 2010 - December 2011</span></div>
            </div>
            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Web Design Intern</h3>
                    <div class="subheading mb-3">Shout! Media Productions</div>
                    <p>Collaboratively administrate empowered markets via plug-and-play networks. Dynamically procrastinate B2C users after installed base benefits. Dramatically visualize customer directed convergence without revolutionary ROI.</p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">September 2008 - June 2010</span></div>
            </div>
        </div>
    </section>
-->
    <hr class="m-0"/>

    <!-- Current position-->
    <section class="resume-section" id="currentposition">
        <div class="resume-section-content">
            <h2 class="mb-5">Current position</h2>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Vision and Computational Cognition lab</h3>
                    <div class="subheading mb-3">Max Planck Institute for Human Cognitive and Brain Sciences · Leipzig, Germany</div>
                    <div class="subheading mb-3">PhD student</div>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">since 2020</span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Max Planck School of Cognition</h3>
                    <div class="subheading mb-3">Doctoral candidate</div>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">since 2019</span></div>
            </div>

        </div>
    </section>

    <hr class="m-0"/>

    <!-- Education-->
    <section class="resume-section" id="education">
        <div class="resume-section-content">
            <h2 class="mb-5">Education</h2>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Max Planck School of Cognition · orientation year</h3>

                    <div class="subheading mb-3">Lab rotations & e-learning</div>
                    <p class="mb-0">Institute of Neuroscience and Medicine at Jülich Research Center (Prof. Simon Eickhoff, Prof. Michael Hanke).</p>
                    <p class="mb-0">Vision and Computational Cognition Group, Max-Planck for Human Cognitive and Brain Sciences (Dr. Martin Hebart).</p>

                </div>
                <div class="flex-shrink-0"><span class="text-primary">2019/20</span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Otto-von-Guericke University Magdeburg · Germany</h3>
                    <div class="subheading mb-3">M. Sc. Psychology</div>
                    <div>Cognitive Neuroscience Track</div>
                    <p class="mb-0">Thesis title: Temporal dynamics and effective connectivity in the distributed system
                        of familiar face processing</p>
                    <p class="mb-0">Thesis supervisors: Prof. Michael Hanke, Prof. Yaroslav O. Halchenko</p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">2018</span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Trier University · Germany</h3>
                    <div class="subheading mb-3">B. Sc. Psychology</div>
                    <p class="mb-0">Thesis title: Top-down modulation of feature integration by long-term memory</p>
                    <p class="mb-0">Thesis supervisors: Prof. Eva Walther, Dr. Katarina Blask</p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">2014</span></div>

            </div>

        </div>
    </section>

    <!-- Skills-->
    <!--
    <section class="resume-section" id="skills">
        <div class="resume-section-content">
            <h2 class="mb-5">Skills</h2>
            <div class="subheading mb-3">Programming Languages & Tools</div>
            <ul class="list-inline dev-icons">
                <li class="list-inline-item"><i class="fab fa-html5"></i></li>
                <li class="list-inline-item"><i class="fab fa-css3-alt"></i></li>
                <li class="list-inline-item"><i class="fab fa-js-square"></i></li>
                <li class="list-inline-item"><i class="fab fa-angular"></i></li>
                <li class="list-inline-item"><i class="fab fa-react"></i></li>
                <li class="list-inline-item"><i class="fab fa-node-js"></i></li>
                <li class="list-inline-item"><i class="fab fa-sass"></i></li>
                <li class="list-inline-item"><i class="fab fa-less"></i></li>
                <li class="list-inline-item"><i class="fab fa-wordpress"></i></li>
                <li class="list-inline-item"><i class="fab fa-gulp"></i></li>
                <li class="list-inline-item"><i class="fab fa-grunt"></i></li>
                <li class="list-inline-item"><i class="fab fa-npm"></i></li>
            </ul>
            <div class="subheading mb-3">Workflow</div>
            <ul class="fa-ul mb-0">
                <li>
                    <span class="fa-li"><i class="fas fa-check"></i></span>
                    Mobile-First, Responsive Design
                </li>
                <li>
                    <span class="fa-li"><i class="fas fa-check"></i></span>
                    Cross Browser Testing & Debugging
                </li>
                <li>
                    <span class="fa-li"><i class="fas fa-check"></i></span>
                    Cross Functional Teams
                </li>
                <li>
                    <span class="fa-li"><i class="fas fa-check"></i></span>
                    Agile Development & Scrum
                </li>
            </ul>
        </div>
    </section>
    -->
    <hr class="m-0"/>

    <!-- Publications-->
    <section class="resume-section" id="contributions">
        <div class="resume-section-content">
            <h2 class="mb-5">Contributions</h2>
            <div class="flex-grow-1">
                <div class="subheading mb-3">Preprints</div>
                <p class="mb-0-h">
                    Contier, O., Baker, C.I., Hebart, M.N. (2023).
                    Distributed representations of behaviorally relevant object dimensions in the human visual system.
                    <i>bioRxiv</i>.
                    <a href="https://doi.org/10.1101/2023.08.23.553812" target="_blank">https://doi.org/10.1101/2023.08.23.553812</a>
                </p>
            </div>
            </br>
            <div class="flex-grow-1">
                <div class="subheading mb-3">Peer-reviewed publications</div>
                <p class="mb-0-h">
                    Kalyani, A., Contier, O., Klemm, L., Azañon, E., Schreiber, S., Speck, O., Reichert, C., Kuehn, E. (2023).
                    Reduced dimension stimulus decoding and column-based modeling reveal architectural differences of primary somatosensory finger maps between younger and older adults.
                    <i>NeuroImage, 283</i>(120430).
                    <a href="https://doi.org/10.1016/j.neuroimage.2023.120430" target="_blank">https://doi.org/10.1016/j.neuroimage.2023.120430</a>
                </p>
                <p class="mb-0-h">
                     Hebart, M.N.<strong>*</strong>, Contier, O.<strong>*</strong>, Teichmann, L.<strong>*</strong>, Rockter, A.H., Zheng, C.Y., Kidder, A., Corriveau, A., Vaziri-Pashkam, M., Baker, C.I. (2023).
                     THINGS-data, a multimodal collection of large-scale datasets for investigating object representations in human brain and behavior.
                    <i>eLife</i>. 12:e82580.
                    <a href="https://doi.org/10.7554/eLife.82580" target="_blank">https://doi.org/10.7554/eLife.82580</a>
                </p>
                <p class="mb-0-h">
                    Fritz, T. H., Schütte, F., Steixner, A., Contier, O., Obrig, H., Villringer, A. (2019). Musical
                    meaning modulates word acquisition. <i>Brain and Language, 190</i>(3). <a
                        href="https://doi.org/10.1016/j.bandl.2018.12.001" target="_blank">https://doi.org/10.1016/j.bandl.2018.12.001</a>
                </p>
                <p class="mb-0-h">
                    Fritz, T. H., Bowling, D. L., Contier, O., Grant, J., Schneider, L., Lederer, A., Hoer, F., Busch,
                    E., & Villringer, A. (2018). Musical agency during exercise decreases pain. <i>Frontiers in
                    Psychology, 8</i>(2312). <a href="https://doi.org/10.3389/fpsyg.2017.02312" target="_blank">https://doi.org/10.3389/fpsyg.2017.02312</a>
                </p>
                <p class="mb-0-h">
                    Sharifian, F., Contier, O., Preuschhof, C., & Pollmann, S. (2017). Reward modulation of contextual
                    cueing: Repeated context overshadows repeated target location. <i>Attention, Perception, &
                    Psychophysics</i>, 79(7). <a href="https://doi.org/10.3758/s13414-017-1397-3" target="_blank">https://doi.org/10.3758/s13414-017-1397-3</a>
                </p>
                <p class="mb-0-h">
                    <i>(<strong>*</strong> equal contribution)</i>
                </p>
            </div>
            </br>
            <div class="flex-grow-1">
                <div class="subheading mb-3">Conference posters</div>
                <p class="mb-0-h">
                    Contier, O., Fujimori, S., Seeliger, K., Murty, N A. R., Hebart, M. (2023, May).
                    <a href="https://doi.org/10.1167/jov.23.9.5356" target=blank>Revealing interpretable object dimensions from a high-throughput model of the fusiform face area.</a>
                    <i>Journal of Vision, 23(23), 5356.</i> https://doi.org/10.1167/jov.23.9.5356
                </p>
                <p class="mb-0-h">
                    Stoinski, L. M., Contier, O., Konkle, T., Hebart, M. N. (2023, May).
                    <a href="https://doi.org/10.1167/jov.23.9.5072" target=blank>Revisiting the animacy, size, and curvature organization of human visual cortex.</a>
                    <i>Journal of Vision, 23(23), 5072.</i> https://doi.org/10.1167/jov.23.9.5072
                </p>
                <p class="mb-0-h">
                    St-Laurent, M., Pinsard, B., Contier, O., Seeliger, K., Borghesani, V., Boyle, J., Bellec, P., Hebart, M. N. (2023, May).
                    <a href="https://doi.org/10.1167/jov.23.9.5424" target=blank>cneuromod-things : a large-scale fMRI dataset for task- and data-driven assessment of object representation and visual memory recognition in the human brain.</a>
                    <i>Journal of Vision, 23(23), 5424.</i> https://doi.org/10.1167/jov.23.9.5424
                </p>
                <p class="mb-0-h">
                    Contier, O., Teichmann, L., Baker, C. I., Hebart, M. N. (2022, June).
                    <a href="assets/img/thingsinitiative_pug2022_poster_lowres.png" target=blank>The THINGS initiative: a global large-scale effort for the representative study of objects in brains, behavior, and computational models.</a>
                    <i>47. Jahrestagung Psychologie und Gehirn 2022, Freiburg</i>
                </p>
                <p class="mb-0-h">
                    Contier, O., Hebart, M. N. (2022, May).
                    <a href="https://doi.org/10.1167/jov.22.14.3951" target=blank>Distributed representation of behaviorally-relevant object dimensions in the human brain.</a>
                    <i>Journal of Vision, 22(14), 3951.</i> https://doi.org/10.1167/jov.22.14.3951
                </p>
                <p class="mb-0-h">
                    Contier, O., Hebart, M. N., Dickter, A. H., Teichmann, L.,
                    Kidder, A., Corriveau, A., Zheng, C., Vaziri-Pashkam, M., Baker, C. I. (2021, November).
                    <a href="assets/img/thingsfmrimeg_sfn_2021_slides.pdf" target=blank>THINGS-fMRI/MEG: A densely sampled multimodal neuroimaging dataset of brain responses to a broad range of natural object images.</a>
                    <i>Society for Neuroscience 50th Annual Meeting, Chicago.</i>
                </p>
                <p class="mb-0-h">
                    Contier, O., Hebart, M. N., Dickter, A. H., Teichmann, L.,
                    Kidder, A., Corriveau, A., Zheng, C., Vaziri-Pashkam, M., Baker, C. I. (2021, September).
                    THINGS-fMRI/MEG: A large-scale multimodal neuroimaging dataset of responses to natural object images.
                    <i>Journal of Vision, 21(9), 2633-2633.</i>
                    <a href="https://doi.org/10.1167/jov.21.9.2633" target=blank>https://doi.org/10.1167/jov.21.9.2633</a>
                </p>
                <p class="mb-0-h">
                  Kalyani, A., Contier, O., Reichert, C., Azañon, E., Kuehn, E. (2021, June).
                  <i>Shared response modelling of S1 digit representations in younger and older adults using 7T fMRI.</i>
                    Organization for Human Brain Mapping (OHBM) 2021 Annual Meeting, Seoul.
                </p>
                <p class="mb-0-h">
                    Contier, O., Kuehn, E., Hanke, M. (2020, June). <i>Shared response modelling of somatosensory digit
                    representations using 7-t fMR</i>. Organization for Human Brain Mapping (OHBM) 2020 Annual Meeting,
                    Montreal. <a
                        href="https://doi.org/10.5281/zenodo.3894834">https://doi.org/10.5281/zenodo.3894834</a>
                </p>
                <p class="mb-0-h">
                    Contier, O., Visconti di Oleggio Castello, M., Gobbini, M. I., Halchenko, Y. O. (2018, June). <i>Temporal
                    dynamics and effective connectivity in the distributed system of familiar face processing</i>.
                    Organization for Human Brain Mapping (OHBM) 2018 Annual Meeting, Singapore. <a
                        href="http://dx.doi.org/10.13140/RG.2.2.17076.96640">http://dx.doi.org/10.13140/RG.2.2.17076.96640</a>
                </p>
            </div>
            </br>
            <div class="flex-grow-1">
                <div class="subheading mb-3">Awards</div>
                <p class="mb-0-h">Open Science Prize, <a href="https://www.dgps.de/fachgruppen/fgbi/aktivitaeten-der-fachgruppe/igor/">Interest Group for Open and Reproducible Research (IGOR)</a>
                  (Division of Biological and Neuropsychology, German Psychological Association), 2022
                </p>
            </div>
          </br>
            <div class="flex-grow-1">
                <div class="subheading mb-3">Ad hoc reviewer</div>    
                   <p class="mb-0">
                        <a href="https://www.nature.com/commsbio" target=blank> Communications Biology</a>,
                        <a href="https://www.nature.com/ncomms/" target=blank> Nature Communications</a>,
                        <a href="https://www.nature.com/sdata/" target=blank> Scientific Data</a>,
                        <a href="https://de.in-mind.org/" target=blank> In-Mind</a>.
                    </p>
            </div>
        </div>
    </section>


    <!-- CV PDF -->
    <!-- <section class="resume-section" id="cv">
        <div class="resume-section-content">
            <h2 class="mb-5">Download CV</h2>
            <div class="embed-responsive embed-responsive-16by9">
                <iframe class="embed-responsive-item" src="assets/doc/cv_contier_website.pdf"></iframe>
            </div>
        </div>
    </section> -->
    <!-- <hr class="m-0"/> -->

    <hr class="m-0"/>

    <section class="resume-section" id="blog">
        <div class="resume-section-content">
            <h2 class="mb-5">Blog</h2>


            <!-- Beginning of Blog post div -->
            <div>
                <h3 class="mb-5">Getting started with HTCondor for data analysis</h3>
                <p class="lead mb-3">
                    I love analyzing data. It's one of my favorite aspects of the job as doctoral student in cognitive
                    neuroscience,
                    and I have a hunch many scientists feel the same.
                    Coming up with methods that make sense of the raw numbers coming out of our measurements can feel
                    like detective work and feel intrinsically rewarding.
                </p>

                <p class="lead mb-3">
                    However, the data we analyze is often too large for our laptops and run-times too long.
                    So we migrate our data and analysis code to the computational cluster our university or institute is
                    hosting.
                    And here, everything is more complicated. The machinery you're trying to use now is shared by a
                    dozen or more people and
                    you have to put in some extra effort and play by the rules to make things run.
                </p>
                <p class="lead mb-3">
                    One common piece of software I've had to get my grips on and which "governs" computational clusters
                    is HTCondor.
                    I've learned to use it through the help of my colleagues and have passed my humble knowledge on to
                    other colleagues since then.
                    To make things easier, I thought I'd release a summary for everybody.
                </p>
                <p class="lead mb-3">
                    Now, you'll find <a href="https://research.cs.wisc.edu/htcondor/manual/" target="_blank">ample
                    documentation</a> on the internet.
                    You can find the relevant commands here along with some more detailed explanation.
                    However - as with all good software - there is a ton of features which you might be confused by and
                    which you'll likely not need in the beginning.
                    So, to get you started, I thought I'd walk through a basic example of how to make your analysis run
                    with Condor.
                </p>
                <p class="lead mb-3">
                    Condor is a quite intelligent system that allows many users of a system to run computational jobs in
                    parallel.
                    It tries to distribute the available resources in a safe, efficient, and somewhat fair manner to all
                    jobs submitted by different users.
                    Think of the jobs as convoys of trucks that want to drive from A to B and the computational
                    resources as all the available lanes on the highway.
                    Condor is the traffic police. You might curse at it sometimes but in the end, it will make your life
                    easier.
                </p>
                <p class="lead mb-3">
                    After you've successfully submitted your jobs to condor, you can disconnect from the cluster, close
                    the terminal, or set your workstation on fire.
                    None of which will terminate your processes.
                </p>
                <p class="lead mb-3">
                    Let's imagine a scenario: Luke and Lea are both PhD students at a top-notch research institution.
                    They work on different projects, but both want to use the computational cluster.
                    Lea wants to run preprocessing on her fMRI data with 30 subjects and Luke wants to do ... something
                    else.
                    The point is, they both want to do a lot of computations! The computing cluster has 15 nodes
                    available, each of which has some fixed amount of memory.
                </p>
                <p class="lead mb-3">
                    Before Luke or Lea get to work, they check what the weather is like today on the cluster. They open
                    a terminal and type ...
                <p class="lead mb-3">
                <pre>condor_status</pre>
                </p>
                </p>
                <p class="lead mb-3">
                    ... which shows them how many computing nodes there are, and how many of them are still free or
                    already in use. They can also type ...
                <p class="lead mb-3">
                <pre>condor_q</pre>
                </p></p>
                <p class="lead mb-3">... which shows them if they themselves have some running jobs and what their
                    status is. Adding the <code>--nobatch</code> flag lets them see all their jobs individually instead
                    of a summary.</p>
                <p class="lead mb-3">Now, Lea gets to work. Her analysis is in a python file called <code>preprocessing.py</code>:
                </p>

                <p class="lead mb-3">
                <pre><code class="code-comment">#! /usr/env/python</code>

<code class="code-func">import</code> time
<code class="code-func">import</code> sys

<code class="code-comment"># the script gets the subject ID as an input argument</code>
subject_id = sys.<code class="code-func">argv</code>[<code class="code-val">1</code>]

print(<code class="code-str">'beep bleep bloop, starting preprocessing'</code>)

time.<code class="code-func">wait</code>(<code class="code-val">60</code>*<code class="code-val">60</code>*<code
                            class="code-val">24</code>)  <code class="code-comment"># complicated calculations going on for 24 hours</code>

<code class="code-func">print</code>(<code class="code-str">'bing bong, finished subject: '</code>, subject_id)</pre>
                </p>
                <p class="lead mb-3">
                    This script executes her preprocessing job for a single subject. She has debugged her code
                    thoroughly and is quite confident it works.
                    She can run the preprocessing for subject <code>sub-01</code> by typing the following in the
                    terminal:</p>

                <pre>python preprocessing.py sub-01</pre>

                <p class="lead mb-3">
                    Specifying the subject ID as the input argument for her script is important, as iterating over input
                    arguments is a simple way to realize paralelization.
                    And she really wansts to run the jobs for as many subjects as possible in parallel, as each one of
                    them takes 24 hours to finish!
                </p>
                <p class="lead mb-3">
                    Some more details on input arguments: Note how the python code sais <code>subject_id =
                    sys.argv[1]</code>.
                    <code>sys.argv</code> can grab the input arguments which the python executable received. <code>sys.argv[0]</code>
                    represents the 0th argument (in our case <code>preprocessing.py</code>).
                    <code>sys.argv[1]</code> represents the 1st argument (in our example <code>sub-01</code>).
                    This is specific for python of course, but other languages/frameworks like bash or matlab could work
                    in a similar manner.
                </p>
                <p class="lead mb-3">
                    To run her jobs on the cluster, Lea does not execute her script directly.
                    She writes a submission file for condor and calls it <code>preprocessing.submit</code>.
                    The simplest version of such a file may look something like this:
                </p>
                <pre>universe = vanilla
executable = /usr/bin/python3  # She wants to run her script with this python version

<code class="code-comment"># She can specify where condor should write some text files for
# error messages, outputs, and logs of the submitted job status.</code>

error = /home/lea/preprocessing.err
output = /home/lea/preprocessing.out
log = /home/lea/preprocessing.log

<code class="code-comment"># Here is the important stuff for paralellization</code>
arguments = /home/lea/preprocessing.py sub-01
queue
arguments = /home/lea/preprocessing.py sub-02
queue
arguments = /home/lea/preprocessing.py sub-03
queue
</pre>

                <p class="lead mb-3">
                    Let's unpack this a bit. You can leave the <code>universe</code> line alone for now.
                    the <code>executable</code> is important and might be the python or matlab version you want to use
                    to execute your script.
                    However, executables can also be scripts you write yourself
                    (e.g. a bash script, see <a
                        href="https://github.com/oliver-contier/famface-temporal-dynamics/blob/master/analysis/extract_eigenvariate.submit"
                        target="_blank">here</a>).
                </p>
                <p class="lead mb-3">
                    <code>error</code>, <code>output</code>, and <code>log</code> are not mandatory, but I would
                    recommend it.
                    Here, condor will put the error messages that are thrown, the standard output of your script (e.g.
                    print/log statements),
                    and some logging detail on how the whole job submission went. Having these helps debugging
                    immensely.
                </p>
                <p class="lead mb-3">
                    The <code>arguments</code> and <code>queue</code> statements are - finally - for
                    <i>paralelization</i>.
                    You see how the first argument (or 0th argument in python's way of counting) is always the path to
                    Lea's preprocessing script.
                    The second argument (i.e. 1st in python) changes depending on what subject is supposed to be
                    preprocessed.
                    Calling <code>queue</code> after <code>arguments</code> merely tells condor to submit a job with
                    these arguments.
                </p>

                <p class="lead mb-3">
                    Alright! Lea's ready to submit her jobs. She types:
                <pre>
condor_submit preprocessing.submit
</pre>
                </p>

                <p class="lead mb-3">
                    Et voila, condor just queued her first three subjects' pipelines as seperate jobs. Lea can look at
                    the current status of her jobs again by typing:
                <pre>condor_q
</pre>
                </p>
                <p class="lead mb-3">
                    Here, she can see how many of her jobs are <code>done</code>, <code>running</code>,
                    <code>idle</code>, or on <code>hold</code>.
                    The meaning of done and running should be self-explanatory ;-) Idle means the job is waiting to be
                    executed.
                    This will definitely happen as soon as Lea submits all 30 subjects, since the computing cluster has
                    only 15 nodes.
                </p>
                <p class="lead mb-3">
                    Hold means something prevents the jobs from running smoothely.
                    One common cause is that permissions for the script are not liberal enough.
                    Lea could try something like...
                </p>
                <pre><code class="code-comment"># give herself executing permissions (should be sufficient)</code>
chmod u+x preprocessing.py
<code class="code-comment"># give herself and her group permissions</code>
chmod ug+x preprocessing.py
<code class="code-comment"># give everybody executing permissions (not recommended)</code>
chmod uga+x preprocessing.py
</pre>
                <p class="lead mb-3">
                    However, there are many thinigs that could go wrong - as always. So it's worth checking out her
                    <code>.err</code> and <code>.log</code> files.
                </p>
                <p class="lead mb-3">
                    Perfect. The next morning, Lea goes to her workstation and is pleased to see that her paralelization
                    for 3 subjects worked fine.
                    She could now just copy and paste the <code>arguments</code>, <code>queue</code> lines in her
                    submission file and change the <code>sub-XY</code> part of it.
                    And let's be honest, I've definitely done that in the past... Just be sure you don't sneak in any
                    typos ;-)
                </p>
                <p class="lead mb-3">
                    Sometims though, Lea might want to submit a ton of jobs or have something like nested paralelization
                    (e.g. <code>sub-01 run-01</code>, <code>sub-1 run-02</code>, <code>sub-02 run-01</code>, ...).
                    In these cases, it gets a bit trickier.
                    One powerful trick is to write a loop in a bash script, which in turn generates a submission file.
                    Let's say we'll call it <code>preprocessing_submitgen.sh</code>:

                <pre><code class="code-comment">#!/usr/bin/env bash

# generate the header, wich is the same for all subjects/runs.</code>
printf <code class="code-str">"universe = vanilla\n"</code>
printf <code class="code-str">"executable = /usr/bin/python3\n"</code>

<code class="code-comment"># iterate over runs and subjects</code>
<code class="code-func">for</code> run <code class="code-func">in</code> <code class="code-val">1 2</code>; <code
                            class="code-func">do</code>
  <code class="code-func">for</code> sub <code class="code-func">in</code> $(seq 1 13); <code
                            class="code-func">do</code>
    printf <code class="code-str">"arguments = /home/lea/preprocessing.py sub-${sub} run-${run}\n"</code>
    printf <code class="code-str">"log       = ${sub}${run}.log\n"</code>
    printf <code class="code-str">"output    = ${sub}${run}.out\n"</code>
    printf <code class="code-str">"error     = ${sub}${run}.err\n"</code>
    printf <code class="code-str">"Queue\n\n"</code>
  <code class="code-func">done</code>
<code class="code-func">done</code>
</pre>
                </p>
                <p class="lead mb-3">
                    In a nutshell, this bash script will generate a standard output that looks like the submission file,
                    if Lea had had the nerves to actually copy and paste all lines until all her combinations of
                    subjects and runs were in there.
                    She can pass this into the condor_submit command with a pipe:
                </p>
                <p class="lead mb-3">
                <pre>bash preprocessing_submitgen.sh | condor_submit
</pre>
                </p>
                <p class="lead mb-3">
                    And that's it! Lea can now submit her jobs and take a nap until her jobs are finished.
                    And naturally, Luke and the other researchers can do the same with their jobs and be at ease,
                    knowing condor will distribute all available resources between them.
                </p>


            </div>
            <!-- End of blog post div -->
        </div>
    </section>


    <!-- Template for list with trophy icons -->
    <!--
    <ul class="fa-ul mb-0">
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            Google Analytics Certified Developer
        </li>
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            Mobile Web Specialist - Google Certification
        </li>
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            1
            <sup>st</sup>
            Place - University of Colorado Boulder - Emerging Tech Competition 2009
        </li>
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            1
            <sup>st</sup>
            Place - University of Colorado Boulder - Adobe Creative Jam 2008 (UI Design Category)
        </li>
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            2
            <sup>nd</sup>
            Place - University of Colorado Boulder - Emerging Tech Competition 2008
        </li>
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            1
            <sup>st</sup>
            Place - James Buchanan High School - Hackathon 2006
        </li>
        <li>
            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
            3
            <sup>rd</sup>
            Place - James Buchanan High School - Hackathon 2005
        </li>
    </ul>
    -->
</div>
</section>
</div>
<!-- Bootstrap core JS-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
<!-- Third party plugin JS-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
<!-- Core theme JS-->
<script src="js/scripts.js"></script>
</body>
</html>
